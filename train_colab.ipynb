{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Snake DQN Training (Colab)\n",
        "\n",
        "Use this notebook on Google Colab to train the Snake DQN and download the checkpoint. Steps:\n",
        "1. Set your git repository URL in the clone cell below.\n",
        "2. Run the setup/install cell to clone the repo and install dependencies.\n",
        "3. Adjust hyperparameters in the args cell if desired.\n",
        "4. Run training.\n",
        "5. Download the trained model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Clone command (token masked): git clone --depth 1 https://github.com/SyntheticVis-Umut/Snake.git /content/Snake\n",
            "CWD: /content/Snake\n",
            "Repository cloned and ready!\n"
          ]
        }
      ],
      "source": [
        "# Clone the repository (set your git URL)\n",
        "import os\n",
        "\n",
        "REPO_URL = os.environ.get(\"SNAKE_REPO_URL\", \"https://github.com/SyntheticVis-Umut/Snake.git\")  # change if using a fork\n",
        "GITHUB_TOKEN = os.environ.get(\"SNAKE_GITHUB_TOKEN\") or os.environ.get(\"GITHUB_TOKEN\")\n",
        "\n",
        "# Clone and setup\n",
        "import shutil\n",
        "import sys\n",
        "import subprocess\n",
        "\n",
        "if not REPO_URL:\n",
        "    raise ValueError(\"Set REPO_URL (or env SNAKE_REPO_URL) before running this cell.\")\n",
        "\n",
        "if os.path.exists('/content/Snake'):\n",
        "    shutil.rmtree('/content/Snake')\n",
        "\n",
        "clone_url = REPO_URL\n",
        "masked_url = REPO_URL\n",
        "if GITHUB_TOKEN and REPO_URL.startswith(\"https://github.com/\"):\n",
        "    # Inject token for private repos (note: token will appear in Colab logs)\n",
        "    clone_url = REPO_URL.replace(\"https://\", f\"https://{GITHUB_TOKEN}@\")\n",
        "    masked_url = REPO_URL.replace(\"https://\", \"https://<TOKEN>@\")\n",
        "    print(\"Using token from env for clone.\")\n",
        "\n",
        "clone_cmd = [\"git\", \"clone\", \"--depth\", \"1\", clone_url, \"/content/Snake\"]\n",
        "print(\"Clone command (token masked):\", \" \".join(clone_cmd).replace(clone_url, masked_url))\n",
        "result = subprocess.run(clone_cmd, capture_output=True, text=True)\n",
        "if result.returncode != 0:\n",
        "    print(\"git clone stdout:\\n\", result.stdout)\n",
        "    print(\"git clone stderr:\\n\", result.stderr)\n",
        "    sys.exit(\"git clone failed; check REPO_URL, token (if private), and permissions\")\n",
        "\n",
        "os.chdir('/content/Snake')\n",
        "\n",
        "# Install deps (CUDA wheels on Colab are handled automatically by torch)\n",
        "%pip install -q pygame torch numpy tqdm\n",
        "\n",
        "print('CWD:', os.getcwd())\n",
        "print('Repository cloned and ready!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pygame 2.6.1 (SDL 2.28.4, Python 3.12.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
            "Imports ok\n"
          ]
        }
      ],
      "source": [
        "# Quick import test\n",
        "from train import train\n",
        "from types import SimpleNamespace\n",
        "print('Imports ok')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure hyperparameters\n",
        "args = SimpleNamespace(\n",
        "    episodes=100000,\n",
        "    max_steps=1000,\n",
        "    buffer_size=50000,\n",
        "    batch_size=512,\n",
        "    gamma=0.99,\n",
        "    lr=5e-4,\n",
        "    eps_start=0.5,\n",
        "    eps_end=0.02,\n",
        "    eps_decay=5000,\n",
        "    target_update=1000,\n",
        "    warmup=2000,\n",
        "    grid=(20, 20),\n",
        "    seed=42,\n",
        "    save_path=\"models/dqn_snake_colab.pt\",\n",
        "    resume=None,  # set to a checkpoint path to continue training\n",
        "    device=\"cuda\",  # force GPU (A100 on Colab); use \"auto\" to fall back\n",
        "    grad_clip=1.0,  # gradient clipping for stability; set <=0 to disable\n",
        "    double_dqn=True,  # use Double DQN targets for better stability\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CUDA device: NVIDIA A100-SXM4-80GB\n",
            "Episode 1/100000 Reward: -2.00 Epsilon: 0.498 Best: -2.00\n",
            "Episode 10/100000 Reward: -3.80 Epsilon: 0.470 Best: -2.00\n",
            "Episode 20/100000 Reward: -11.90 Epsilon: 0.444 Best: -2.00\n",
            "Episode 30/100000 Reward: -12.40 Epsilon: 0.421 Best: -2.00\n",
            "Episode 40/100000 Reward: -13.80 Epsilon: 0.393 Best: -2.00\n",
            "Episode 50/100000 Reward: -12.50 Epsilon: 0.377 Best: -2.00\n",
            "Episode 60/100000 Reward: -12.50 Epsilon: 0.366 Best: -2.00\n",
            "Episode 70/100000 Reward: -11.10 Epsilon: 0.352 Best: -2.00\n",
            "Episode 80/100000 Reward: -11.50 Epsilon: 0.334 Best: -2.00\n",
            "Episode 90/100000 Reward: -12.20 Epsilon: 0.299 Best: -2.00\n",
            "Episode 100/100000 Reward: -6.00 Epsilon: 0.270 Best: 0.30\n",
            "Episode 110/100000 Reward: -3.50 Epsilon: 0.246 Best: 10.50\n",
            "Episode 120/100000 Reward: -12.50 Epsilon: 0.211 Best: 14.40\n",
            "Episode 130/100000 Reward: -11.30 Epsilon: 0.196 Best: 14.40\n",
            "Episode 140/100000 Reward: 2.70 Epsilon: 0.172 Best: 46.30\n",
            "Episode 150/100000 Reward: -2.80 Epsilon: 0.152 Best: 53.90\n",
            "Episode 160/100000 Reward: -16.40 Epsilon: 0.133 Best: 53.90\n",
            "Episode 170/100000 Reward: 15.70 Epsilon: 0.117 Best: 84.40\n",
            "Episode 180/100000 Reward: 53.80 Epsilon: 0.100 Best: 91.10\n",
            "Episode 190/100000 Reward: 93.90 Epsilon: 0.081 Best: 118.00\n",
            "Episode 200/100000 Reward: 202.10 Epsilon: 0.061 Best: 202.10\n",
            "Episode 210/100000 Reward: 142.80 Epsilon: 0.048 Best: 202.10\n",
            "Episode 220/100000 Reward: 213.30 Epsilon: 0.036 Best: 272.00\n",
            "Episode 230/100000 Reward: 64.10 Epsilon: 0.030 Best: 272.00\n",
            "Episode 240/100000 Reward: 103.30 Epsilon: 0.026 Best: 281.30\n",
            "Episode 250/100000 Reward: 75.50 Epsilon: 0.023 Best: 281.30\n",
            "Episode 260/100000 Reward: 111.50 Epsilon: 0.022 Best: 360.00\n",
            "Episode 270/100000 Reward: 68.50 Epsilon: 0.021 Best: 360.00\n",
            "Episode 280/100000 Reward: 208.80 Epsilon: 0.021 Best: 360.00\n",
            "Episode 290/100000 Reward: 148.80 Epsilon: 0.020 Best: 360.00\n",
            "Episode 300/100000 Reward: 78.50 Epsilon: 0.020 Best: 360.00\n",
            "Episode 310/100000 Reward: 142.40 Epsilon: 0.020 Best: 360.00\n",
            "Episode 320/100000 Reward: 221.30 Epsilon: 0.020 Best: 360.00\n",
            "Episode 330/100000 Reward: 53.70 Epsilon: 0.020 Best: 386.20\n",
            "Episode 340/100000 Reward: 188.20 Epsilon: 0.020 Best: 386.20\n",
            "Episode 350/100000 Reward: 55.80 Epsilon: 0.020 Best: 386.20\n",
            "Episode 360/100000 Reward: 16.40 Epsilon: 0.020 Best: 386.20\n",
            "Episode 370/100000 Reward: 120.70 Epsilon: 0.020 Best: 386.20\n",
            "Episode 380/100000 Reward: 55.10 Epsilon: 0.020 Best: 386.20\n",
            "Episode 390/100000 Reward: 69.60 Epsilon: 0.020 Best: 386.20\n",
            "Episode 400/100000 Reward: 34.20 Epsilon: 0.020 Best: 386.20\n",
            "Episode 410/100000 Reward: 227.90 Epsilon: 0.020 Best: 386.20\n",
            "Episode 420/100000 Reward: 125.90 Epsilon: 0.020 Best: 386.20\n",
            "Episode 430/100000 Reward: 193.30 Epsilon: 0.020 Best: 386.20\n",
            "Episode 440/100000 Reward: 235.10 Epsilon: 0.020 Best: 386.20\n",
            "Episode 450/100000 Reward: 233.80 Epsilon: 0.020 Best: 386.20\n",
            "Episode 460/100000 Reward: 191.50 Epsilon: 0.020 Best: 386.20\n",
            "Episode 470/100000 Reward: 93.50 Epsilon: 0.020 Best: 386.20\n",
            "Episode 480/100000 Reward: 259.20 Epsilon: 0.020 Best: 386.20\n",
            "Episode 490/100000 Reward: 78.30 Epsilon: 0.020 Best: 386.20\n",
            "Episode 500/100000 Reward: 307.70 Epsilon: 0.020 Best: 386.20\n"
          ]
        }
      ],
      "source": [
        "# Train\n",
        "train(args)\n",
        "print('Training done, saved to', args.save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download the trained model (Colab)\n",
        "from google.colab import files\n",
        "files.download(args.save_path)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
